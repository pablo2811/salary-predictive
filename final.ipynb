{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix , classification_report, roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import category_encoders as ce\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#import ssl # probably not needed on your machine, delete before release\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context # probably not needed on your machine, delete before release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://lovespreadsheet-tutorials.s3.amazonaws.com/APIDatasets/census_income_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    df[df == \"?\"] = np.nan\n",
    "    df.dropna(inplace = True)\n",
    "    data = df.drop([\"fnlwgt\", \"income_level\"], axis=1)\n",
    "    target = np.array(df[\"income_level\"])\n",
    "    return data,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(df,test_size_fraction):\n",
    "    data, target = pre_process(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target,\n",
    "                                                        test_size = test_size_fraction,\n",
    "                                                        random_state = 42,\n",
    "                                                       stratify=target)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_marital(df):\n",
    "    res = df.copy()\n",
    "    res['marital_status'] = res['marital_status'].replace(\n",
    "        ['Widowed', 'Divorced', 'Separated', 'Never-married', 'Married-spouse-absent'], 'Living-Alone')\n",
    "    res['marital_status'] = res['marital_status'].replace(\n",
    "        ['Married-civ-spouse', 'Married-AF-spouse'], 'Married')\n",
    "    return res\n",
    "\n",
    "def grouping_ethnic(df):\n",
    "    res = df.copy()\n",
    "    res['race'] = res['race'].replace(['Asian-Pac-Islander', 'White'], '1stGroup')\n",
    "    res['race'] = res['race'].replace(['Other', 'Black', 'Amer-Indian-Eskimo'], '2ndGroup')\n",
    "    return res\n",
    "\n",
    "def grouping_education(df):\n",
    "    res = df.copy()\n",
    "    res['education'] = res['education'].replace(\n",
    "            ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th'], 'Obligatory')\n",
    "    res['education'] = res['education'].replace(['HS-grad', 'Some-college'], 'HS-college')\n",
    "    res['education'] = res['education'].replace(['Assoc-voc', 'Assoc-acdm'], 'Assoc')\n",
    "    res['education'] = res['education'].replace(['Prof-school', 'Doctorate'], 'Academic')\n",
    "    return res\n",
    "\n",
    "def grouping_countries(df):\n",
    "    countries_list = grouping_countries_helper(df)\n",
    "    res = df.copy()\n",
    "    res.loc[~res['native_country'].isin(countries_list), \"native_country\"] = \"Other\"\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[:11], 'Low-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[11:17], 'Lower-middle-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[17:23], 'Middle-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[23:26], 'Upper-middle-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[26:32]+countries_list[33:], 'High-income')\n",
    "    return res\n",
    "\n",
    "def grouping_countries_helper(df):\n",
    "    gdp = pd.read_csv(\"gdp.csv\", sep=\";\")\n",
    "    df2 = df.copy()\n",
    "    df2[\"income_level\"] = df2.loc[:,\"income_level\"].map({'<=50K': 0, '>50K': 1})\n",
    "    df2 = df2.groupby(\"native_country\")[\"income_level\"].mean().reset_index()\n",
    "    countries = pd.merge(df2, gdp, left_on = \"native_country\", right_on = \"Country\", how = \"left\").sort_values(by = \"GDP95\")\n",
    "    countries_list = list(countries[\"native_country\"])\n",
    "    return countries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,data,label=None):\n",
    "    if label is None:\n",
    "        label = \"\"\n",
    "    X_train,X_test,y_train,y_test = get_split(data,0.2)\n",
    "    kfolds = 8\n",
    "    split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "    test_model = get_pipeline(model)\n",
    "    cv_results = cross_val_score(test_model, \n",
    "                     X_train.drop(\"education_num\", axis=1), y_train, \n",
    "                     cv=split,\n",
    "                     scoring=\"accuracy\",\n",
    "                     n_jobs=-1)\n",
    "    \n",
    "    print(f\" {label} cross validation accuarcy score: {round(np.mean(cv_results), 4)}\\\n",
    "        +/- {round(np.std(cv_results), 4)} (std) \\t min: {round(min(cv_results), 4)},\\\n",
    "        max: {round(max(cv_results), 4)}\")\n",
    "    \n",
    "    test_model.fit(X_train, y_train)\n",
    "    return test_model.predict(X_test), test_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def get_pipeline(model):\n",
    "    cat_features = [\"workclass\", \"education\", \"marital_status\",\n",
    "                    \"occupation\", \"relationship\", \"race\", \n",
    "                    \"sex\", \"native_country\"]     \n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "        [\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown = 'ignore'), cat_features), \n",
    "        (\"std_scaler\", StandardScaler(), [\"age\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"])\n",
    "        ],\n",
    "        remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "    model_pipeline = Pipeline(\n",
    "        [\n",
    "            ('transformer', transformer),\n",
    "            ('model', model)\n",
    "        ]\n",
    "    )\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " grouping_marital cross validation accuarcy score: 0.8485        +/- 0.0046 (std) \t min: 0.8421,        max: 0.8565\n",
      " grouping_ethnic cross validation accuarcy score: 0.8484        +/- 0.0041 (std) \t min: 0.8434,        max: 0.8549\n",
      " grouping_education cross validation accuarcy score: 0.8482        +/- 0.0047 (std) \t min: 0.8417,        max: 0.8554\n",
      " grouping_countries cross validation accuarcy score: 0.8463        +/- 0.0057 (std) \t min: 0.8341,        max: 0.8521\n"
     ]
    }
   ],
   "source": [
    "transformations = [grouping_marital,grouping_ethnic,grouping_education,grouping_countries]\n",
    "transformations_names = [\"grouping_marital\",\"grouping_ethnic\",\"grouping_education\",\"grouping_countries\"]\n",
    "model = LogisticRegression(random_state=42, n_jobs=-1,max_iter=500)\n",
    "for transformation, name in zip(transformations,transformations_names):\n",
    "    transformed_data = transformation(df)\n",
    "    test_model(model, transformed_data,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bazujących na tych wynikach, wybieramy `grouping_marital` jako docelowy sposób grupowania kategorycznego. Doświadczenia z poprzednich etapów prac, wskazały, że wielokrotne składanie grupowań nie pozwala osiągnać wyższej precyzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_tuned_model(df,model_type, param_test, param_grid, name):\n",
    "    best_params = parse_params(get_best_params(model_type, param_test, param_grid, df))\n",
    "    #best_params.update(class_weight= {'<=50K': 1 , '>50K': 1.5})\n",
    "    #print(best_params)\n",
    "    designated_model = model_type(**best_params)\n",
    "    transformed_data = grouping_marital(df)\n",
    "    y_hat, y_hat_proba = test_model(designated_model,transformed_data,name)\n",
    "    return y_hat, y_hat_proba, designated_model\n",
    "\n",
    "def result_tuned_model(df,model, name):\n",
    "    transformed_data = grouping_marital(df)\n",
    "    y_hat, y_hat_proba = test_model(model,transformed_data,name)\n",
    "    return y_hat, y_hat_proba, model\n",
    "    \n",
    "def get_best_params(model_type, param_test, param_grid, df):\n",
    "    test_model = model_type(**param_test)\n",
    "    pipeline = get_pipeline(test_model)\n",
    "    randomizer = RandomizedSearchCV(pipeline, param_grid, cv=3, n_iter=5)\n",
    "    X_train, X_test, y_train, y_test = get_split(grouping_marital(df),0.2)\n",
    "    randomizer.fit(X_train,y_train)\n",
    "    return randomizer.best_params_\n",
    "\n",
    "\n",
    "def parse_params(best_params):\n",
    "    parsed_dicitionary_params = dict()\n",
    "    for k in best_params.keys():\n",
    "        parsed_dicitionary_params[k.replace(\"model__\",\"\")] = best_params[k]\n",
    "    parsed_dicitionary_params[\"random_state\"] = 42\n",
    "    parsed_dicitionary_params[\"n_jobs\"] = -1\n",
    "    return parsed_dicitionary_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    'model__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'model__max_iter': [1000],\n",
    "    'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "                }\n",
    "\n",
    "param_test_lr = {\n",
    "                \"random_state\": 42,\n",
    "                \"max_iter\": 1000,\n",
    "                 \"n_jobs\": -1\n",
    "                }\n",
    "\n",
    "param_test_rf = {\n",
    "                \"random_state\": 42,\n",
    "                 \"n_jobs\": -1\n",
    "                }\n",
    "\n",
    "param_test_xgb = {\n",
    "                \"random_state\": 42,\n",
    "                }\n",
    "\n",
    "param_grid_rf = {\n",
    "            \"model__max_depth\": [3, None],\n",
    "            \"model__max_features\": [1, 3, 10],\n",
    "            \"model__min_samples_leaf\": [1, 3, 10],\n",
    "            \"model__bootstrap\": [True, False],\n",
    "            \"model__criterion\": [\"gini\", \"entropy\"]\n",
    "                }\n",
    "param_grid_xgb = {\n",
    "            \"model__max_depth\": [3, 6, 9],\n",
    "            \"model__eta\": [0.2, 0.25, 0.3, 0.35],\n",
    "            \"model__reg_lambda\": [0.01, 0.1, 1, 10],\n",
    "            \"model__scale_pos_weight\": [1/2, 1, 2],\n",
    "            \"model__booster\": [\"gbtree\", \"dart\"],\n",
    "            \"model__rate_drop\" : [0.0, 0.1, 0.2],\n",
    "            \"model__eval_metric\": [\"logloss\", \"rmsle\"]\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RandomForestClassifier cross validation accuarcy score: 0.8628        +/- 0.0036 (std) \t min: 0.8578,        max: 0.8686\n"
     ]
    }
   ],
   "source": [
    "y_hat_Rf, y_hat_prob_Rf, model_Rf = result_tuned_model(df,RandomForestClassifier,\n",
    "                                             param_test_rf,param_grid_rf,\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LogisticRegression cross validation accuarcy score: 0.8485        +/- 0.0047 (std) \t min: 0.8419,        max: 0.8565\n"
     ]
    }
   ],
   "source": [
    "y_hat_Lr, y_hat_prob_Lr, model_Lr =  result_tuned_model(df,LogisticRegression,\n",
    "                                              param_test_lr, param_grid_lr,\"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGBClassifier cross validation accuarcy score: 0.8684        +/- 0.0051 (std) \t min: 0.86,        max: 0.8766\n"
     ]
    }
   ],
   "source": [
    "y_hat_Gb, y_hat_prob_Gb, model_Gb =  result_tuned_model(df,XGBClassifier,\n",
    "                                              param_test_xgb, param_grid_xgb,\"XGBClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_split(grouping_marital(df),0.2) #jescze raz dzilemy set aby miec dostep to \n",
    "                                                                       #test setów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulit in:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.88      0.94      0.91      6803\n",
      "        >50K       0.77      0.60      0.68      2242\n",
      "\n",
      "    accuracy                           0.86      9045\n",
      "   macro avg       0.82      0.77      0.79      9045\n",
      "weighted avg       0.85      0.86      0.85      9045\n",
      "\n",
      "Roc_Auc_Score: 0.9155707136078785\n",
      "\n",
      "Confusion matrix:\n",
      " [[6399  404]\n",
      " [ 886 1356]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bulit in:\\n {classification_report(y_test, y_hat_Rf)}\")\n",
    "print(f\"Roc_Auc_Score: {roc_auc_score(y_test, y_hat_prob_Rf)}\\n\")\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(y_test, y_hat_Rf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulit in:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.87      0.93      0.90      6803\n",
      "        >50K       0.73      0.59      0.65      2242\n",
      "\n",
      "    accuracy                           0.84      9045\n",
      "   macro avg       0.80      0.76      0.77      9045\n",
      "weighted avg       0.84      0.84      0.84      9045\n",
      "\n",
      "Roc_Auc_Score: 0.9013086266317676\n",
      "\n",
      "Confusion matrix:\n",
      " [[6310  493]\n",
      " [ 930 1312]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bulit in:\\n {classification_report(y_test, y_hat_Lr)}\")\n",
    "print(f\"Roc_Auc_Score: {roc_auc_score(y_test, y_hat_prob_Lr)}\\n\")\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(y_test, y_hat_Lr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulit in:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.94      0.91      6803\n",
      "        >50K       0.78      0.65      0.71      2242\n",
      "\n",
      "    accuracy                           0.87      9045\n",
      "   macro avg       0.84      0.79      0.81      9045\n",
      "weighted avg       0.86      0.87      0.86      9045\n",
      "\n",
      "Roc_Auc_Score: 0.9265574640877726\n",
      "\n",
      "Confusion matrix:\n",
      " [[6402  401]\n",
      " [ 789 1453]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bulit in:\\n {classification_report(y_test, y_hat_Gb)}\")\n",
    "print(f\"Roc_Auc_Score: {roc_auc_score(y_test, y_hat_prob_Gb)}\\n\")\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(y_test, y_hat_Gb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('RFC', model_Rf), ('LR', model_Lr), ('XGB', model_Gb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_soft = VotingClassifier(estimators= estimators, voting='soft', weights = [0.1, 0.1, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model_soft cross validation accuarcy score: 0.8713        +/- 0.0051 (std) \t min: 0.8644,        max: 0.8793\n",
      "[13:16:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { rate_drop } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_v, y_hat_prob_v, model_v = result_tuned_model(df,model_soft, \"model_soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulit in:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.94      0.91      6803\n",
      "        >50K       0.79      0.64      0.70      2242\n",
      "\n",
      "    accuracy                           0.87      9045\n",
      "   macro avg       0.84      0.79      0.81      9045\n",
      "weighted avg       0.86      0.87      0.86      9045\n",
      "\n",
      "Roc_Auc_Score: 0.9256260323835197\n",
      "\n",
      "Confusion matrix:\n",
      " [[6413  390]\n",
      " [ 811 1431]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bulit in:\\n {classification_report(y_test, y_hat_v)}\")\n",
    "print(f\"Roc_Auc_Score: {roc_auc_score(y_test, y_hat_prob_v)}\\n\")\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(y_test, y_hat_v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df.copy()\n",
    "#target_encoder = ce.TargetEncoder()\n",
    "#target_encoder1 = ce.TargetEncoder()\n",
    "#target_encoder2 = ce.TargetEncoder()\n",
    "#target_encoder3 = ce.TargetEncoder()\n",
    "#target_encoder4 = ce.TargetEncoder()\n",
    "#target_encoder5 = ce.TargetEncoder()\n",
    "#target_encoder6 = ce.TargetEncoder()\n",
    "#target_encoder7 = ce.TargetEncoder()\n",
    "#cat_features = [\"workclass\", \"education\", \"marital_status\",\n",
    "#                    \"occupation\", \"relationship\", \"race\", \n",
    "#                    \"sex\", \"native_country\"]\n",
    "#df1[\"income_level\"] = df1.loc[:,\"income_level\"].map({'<=50K': 0, '>50K': 1})\n",
    "#df1[\"workclass\"] = target_encoder.fit_transform(df1[\"workclass\"], df1[\"income_level\"])\n",
    "#df1[\"education\"] = target_encoder1.fit_transform(df1[\"education\"], df1[\"income_level\"])\n",
    "#df1[\"marital_status\"] = target_encoder2.fit_transform(df1[\"marital_status\"], df1[\"income_level\"])\n",
    "#df1[\"occupation\"] = target_encoder3.fit_transform(df1[\"occupation\"], df1[\"income_level\"])\n",
    "#df1[\"relationship\"] = target_encoder4.fit_transform(df1[\"relationship\"], df1[\"income_level\"])\n",
    "#df1[\"race\"] = target_encoder5.fit_transform(df1[\"race\"], df1[\"income_level\"])\n",
    "#df1[\"sex\"] = target_encoder6.fit_transform(df1[\"sex\"], df1[\"income_level\"])\n",
    "#df1[\"native_country\"] = target_encoder7.fit_transform(df1[\"native_country\"], df1[\"income_level\"])\n",
    "#X_c, y_c = pre_process(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf = PolynomialFeatures(degree=1)\n",
    "#X_features = pf.fit_transform(X_c)\n",
    "#listFeat = pf.get_feature_names(X_c.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def feature_names(selector):\n",
    "#    return np.array(pf.get_feature_names(X_c.columns))[selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def indexBest(k, bestFeat, listFeat):\n",
    "#    chi2_selector = SelectKBest(chi2, k=k)\n",
    "#    chi2_selector.fit_transform(X_features, y_c)\n",
    "#    bestFeat = feature_names(chi2_selector)\n",
    "#    indexs = []\n",
    "#    for el in bestFeat:\n",
    "#        idx = listFeat.index(el)\n",
    "#        indexs.append(idx)\n",
    "#    return indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = indexBest(10, bestFeat, listFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_c = pd.DataFrame(np.matrix(X_features)[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tr, X_te, y_tr, y_te = train_test_split(X_c, y_c,\n",
    "#                        test_size = 0.2,\n",
    "#                        random_state = 42,\n",
    "#                        stratify= y_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6922,  509],\n",
       "       [1023, 1315]])"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lr = LogisticRegression()\n",
    "#lr.fit(X_tr, y_tr)\n",
    "#y_hat = lr.predict(X_te)\n",
    "#confusion_matrix(y_te, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      7431\n",
      "           1       0.72      0.56      0.63      2338\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.80      0.75      0.77      9769\n",
      "weighted avg       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(classification_report(y_te, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
