{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawelf/snap/jupyter/common/lib/python3.7/site-packages/joblib/_multiprocessing_helpers.py:45: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import ssl # probably not needed on your machine, delete before release\n",
    "ssl._create_default_https_context = ssl._create_unverified_context # probably not needed on your machine, delete before release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://lovespreadsheet-tutorials.s3.amazonaws.com/APIDatasets/census_income_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    df[df == \"?\"] = np.nan\n",
    "    df.dropna(inplace = True)\n",
    "    data = df.drop([\"fnlwgt\", \"income_level\"], axis=1)\n",
    "    target = np.array(df[\"income_level\"])\n",
    "    return data,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(df,test_size_fraction):\n",
    "    data, target = pre_process(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target,\n",
    "                                                        test_size = test_size_fraction,\n",
    "                                                        random_state = 42,\n",
    "                                                       stratify=target)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_marital(df):\n",
    "    res = df.copy()\n",
    "    res['marital_status'] = res['marital_status'].replace(\n",
    "        ['Widowed', 'Divorced', 'Separated', 'Never-married', 'Married-spouse-absent'], 'Living-Alone')\n",
    "    res['marital_status'] = res['marital_status'].replace(\n",
    "        ['Married-civ-spouse', 'Married-AF-spouse'], 'Married')\n",
    "    return res\n",
    "\n",
    "def grouping_ethnic(df):\n",
    "    res = df.copy()\n",
    "    res['race'] = res['race'].replace(['Asian-Pac-Islander', 'White'], '1stGroup')\n",
    "    res['race'] = res['race'].replace(['Other', 'Black', 'Amer-Indian-Eskimo'], '2ndGroup')\n",
    "    return res\n",
    "\n",
    "def grouping_education(df):\n",
    "    res = df.copy()\n",
    "    res['education'] = res['education'].replace(\n",
    "            ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th'], 'Obligatory')\n",
    "    res['education'] = res['education'].replace(['HS-grad', 'Some-college'], 'HS-college')\n",
    "    res['education'] = res['education'].replace(['Assoc-voc', 'Assoc-acdm'], 'Assoc')\n",
    "    res['education'] = res['education'].replace(['Prof-school', 'Doctorate'], 'Academic')\n",
    "    return res\n",
    "\n",
    "def grouping_countries(df):\n",
    "    countries_list = grouping_countries_helper(df)\n",
    "    res = df.copy()\n",
    "    res.loc[~res['native_country'].isin(countries_list), \"native_country\"] = \"Other\"\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[:11], 'Low-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[11:17], 'Lower-middle-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[17:23], 'Middle-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[23:26], 'Upper-middle-income')\n",
    "    res['native_country'] = res['native_country'].replace(countries_list[26:32]+countries_list[33:], 'High-income')\n",
    "    return res\n",
    "\n",
    "def grouping_countries_helper(df):\n",
    "    gdp = pd.read_csv(\"gdp.csv\", sep=\";\")\n",
    "    df2 = df.copy()\n",
    "    df2[\"income_level\"] = df2.loc[:,\"income_level\"].map({'<=50K': 0, '>50K': 1})\n",
    "    df2 = df2.groupby(\"native_country\")[\"income_level\"].mean().reset_index()\n",
    "    countries = pd.merge(df2, gdp, left_on = \"native_country\", right_on = \"Country\", how = \"left\").sort_values(by = \"GDP95\")\n",
    "    countries_list = list(countries[\"native_country\"])\n",
    "    return countries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,data,label=None):\n",
    "    if label is None:\n",
    "        label = \"\"\n",
    "    X_train,X_test,y_train,y_test = get_split(data,0.2)\n",
    "    kfolds = 8\n",
    "    split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "    cv_results = cross_val_score(get_pipeline(model), \n",
    "                     X_train.drop(\"education_num\", axis=1), y_train, \n",
    "                     cv=split,\n",
    "                     scoring=\"accuracy\",\n",
    "                     n_jobs=-1)\n",
    "    \n",
    "    print(f\" {label} cross validation accuarcy score: {round(np.mean(cv_results), 4)} +/- {round(np.std(cv_results), 4)} (std) \\t min: {round(min(cv_results), 4)}, max: {round(max(cv_results), 4)}\")\n",
    "    \n",
    "def get_pipeline(model):\n",
    "    cat_features = [\"workclass\", \"education\", \"marital_status\",\n",
    "                    \"occupation\", \"relationship\", \"race\", \n",
    "                    \"sex\", \"native_country\"]     \n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "        [\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown = 'ignore'), cat_features), \n",
    "        (\"std_scaler\", StandardScaler(), [\"age\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"])\n",
    "        ],\n",
    "        remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "    model_pipeline = Pipeline(\n",
    "        [\n",
    "            ('transformer', transformer),\n",
    "            ('model', model)\n",
    "        ]\n",
    "    )\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " grouping_marital cross validation accuarcy score: 0.8484 +/- 0.0046 (std) \t min: 0.8421, max: 0.8563\n",
      " grouping_ethnic cross validation accuarcy score: 0.8483 +/- 0.0041 (std) \t min: 0.8432, max: 0.8549\n",
      " grouping_education cross validation accuarcy score: 0.8482 +/- 0.0047 (std) \t min: 0.8417, max: 0.8554\n",
      " grouping_countries cross validation accuarcy score: 0.8462 +/- 0.0057 (std) \t min: 0.8341, max: 0.8518\n"
     ]
    }
   ],
   "source": [
    "transformations = [grouping_marital,grouping_ethnic,grouping_education,grouping_countries]\n",
    "transformations_names = [\"grouping_marital\",\"grouping_ethnic\",\"grouping_education\",\"grouping_countries\"]\n",
    "model = LogisticRegression(random_state=42, n_jobs=-1,max_iter=500)\n",
    "for transformation, name in zip(transformations,transformations_names):\n",
    "    transformed_data = transformation(df)\n",
    "    test_model(model, transformed_data,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bazujących na tych wynikach, wybieramy `grouping_marital` jako docelowy sposób grupowania kategorycznego. Doświadczenia z poprzednich etapów prac, wskazały, że wielokrotne składanie grupowań nie pozwala osiągnać wyższej precyzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_tuned_model(df,model_type, param_test, param_grid, name):\n",
    "    best_params = parse_params(get_best_params(model_type, param_test, param_grid, df))\n",
    "    designated_model = model_type(**best_params)\n",
    "    transformed_data = grouping_marital(df)\n",
    "    test_model(designated_model,transformed_data,name)\n",
    "    \n",
    "    \n",
    "def get_best_params(model_type, param_test, param_grid, df):\n",
    "    test_model = model_type(**param_test)\n",
    "    pipeline = get_pipeline(test_model)\n",
    "    randomizer = RandomizedSearchCV(pipeline, param_grid, cv=3, n_iter=5)\n",
    "    X_train, X_test, y_train, y_test = get_split(grouping_marital(df),0.2)\n",
    "    randomizer.fit(X_train,y_train)\n",
    "    return randomizer.best_params_\n",
    "\n",
    "\n",
    "def parse_params(best_params):\n",
    "    parsed_dicitionary_params = dict()\n",
    "    for k in best_params.keys():\n",
    "        parsed_dicitionary_params[k.replace(\"model__\",\"\")] = best_params[k]\n",
    "    parsed_dicitionary_params[\"random_state\"] = 42\n",
    "    parsed_dicitionary_params[\"n_jobs\"] = -1\n",
    "    return parsed_dicitionary_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    'model__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'model__max_iter': [1000],\n",
    "    'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "                }\n",
    "\n",
    "param_test_lr = {\n",
    "                \"random_state\": 42,\n",
    "                \"max_iter\": 1000,\n",
    "                 \"n_jobs\": -1\n",
    "                }\n",
    "param_test_rf = {\n",
    "                \"random_state\": 42,\n",
    "                 \"n_jobs\": -1\n",
    "                }\n",
    "param_grid_rf = {\n",
    "            \"model__max_depth\": [3, None],\n",
    "            \"model__max_features\": [1, 3, 10],\n",
    "            \"model__min_samples_leaf\": [1, 3, 10],\n",
    "            \"model__bootstrap\": [True, False],\n",
    "            \"model__criterion\": [\"gini\", \"entropy\"]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RandomForestClassifier cross validation accuarcy score: 0.862 +/- 0.0036 (std) \t min: 0.856, max: 0.8675\n"
     ]
    }
   ],
   "source": [
    "result_tuned_model(df,RandomForestClassifier,param_test_rf,param_grid_rf,\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tuned_model(df,LogisticRegression,param_test_lr, param_grid_lr,\"LogisticRegression\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
